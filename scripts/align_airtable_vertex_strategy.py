#!/usr/bin/env python3
"""
Align AirTable with Smart Vertex AI Architecture ($442/month solution)
Updates all Vertex AI related tasks to reflect the new tiered deployment strategy
"""

import os
import json
from pyairtable import Api
from datetime import datetime

# Load environment variables
AIRTABLE_API_KEY = os.environ.get('AIRTABLE_API_KEY')
if not AIRTABLE_API_KEY:
    print("Error: AIRTABLE_API_KEY environment variable not set")
    print("Please set: export AIRTABLE_API_KEY='your_key_here'")
    exit(1)

BASE_ID = 'app3tpP9F3BrP1P7j'

api = Api(AIRTABLE_API_KEY)
tasks_table = api.table(BASE_ID, 'Tasks')

# Define the new Smart Vertex AI task structure
SMART_VERTEX_TASKS = {
    'P03_S01': {  # Vertex AI Smart Architecture Phase
        'tasks': [
            {
                'name': 'T03.01 - Deploy 5 Critical Vertex AI Endpoints',
                'description': 'Deploy only 5 high-traffic currency pair endpoints (EUR_USD_90, GBP_USD_90, USD_JPY_90, EUR_GBP_90, EUR_JPY_90) using n1-standard-2 machines for real-time predictions. Cost: $342/month.',
                'notes': 'Critical endpoints only for highest volume pairs. Using 90-minute windows for optimal RÂ² performance. Deploy with min_replicas=1, max_replicas=2 for auto-scaling. Total CPU usage: 10 CPUs.',
                'priority': 'Critical',
                'status': 'In Progress',
                'artifacts': 'deploy_critical_endpoints.py, endpoint_configs.json',
                'assigned_to': 'BA'
            },
            {
                'name': 'T03.02 - Configure Vertex AI Batch Predictions',
                'description': 'Setup batch prediction jobs for 191 remaining models. Configure hourly batch processing using Vertex AI batch prediction API. Cost: $100/month.',
                'notes': 'Batch predictions for all non-critical pairs and time windows. Uses n1-standard-4 machines for batch processing. Results cached in BigQuery for fast retrieval.',
                'priority': 'High',
                'status': 'Pending',
                'artifacts': 'setup_batch_predictions.py, batch_configs.json',
                'assigned_to': 'BA'
            },
            {
                'name': 'T03.03 - Create Cloud Scheduler for Batch Jobs',
                'description': 'Configure Cloud Scheduler to trigger hourly batch predictions. Setup Pub/Sub topics for job orchestration. Cost: $10/month.',
                'notes': 'Hourly cron job (0 * * * *) to refresh all batch predictions. Ensures data freshness while minimizing compute costs.',
                'priority': 'High',
                'status': 'Pending',
                'artifacts': 'setup_scheduler.py, cron_configs.yaml',
                'assigned_to': 'BA'
            },
            {
                'name': 'T03.04 - Deploy Cloud Functions Unified API',
                'description': 'Create Cloud Functions API to serve all 196 model predictions through single endpoint. Routes to real-time endpoints or batch cache based on model. Cost: $20/month.',
                'notes': 'Unified API checks if model is critical (use endpoint) or standard (use batch cache). Returns predictions with <50ms latency from cache, <100ms from endpoints.',
                'priority': 'High',
                'status': 'Pending',
                'artifacts': 'get_prediction/main.py, function_config.yaml',
                'assigned_to': 'BA'
            },
            {
                'name': 'T03.05 - Implement BigQuery Prediction Cache',
                'description': 'Setup BigQuery tables to cache batch predictions and endpoint results. Optimize for fast retrieval with proper indexing. Cost: $20/month storage.',
                'notes': 'Cache structure: predictions.batch_{model_name} tables. Hourly partitioning for efficient queries. Automatic expiry for old predictions.',
                'priority': 'Medium',
                'status': 'Pending',
                'artifacts': 'create_cache_tables.sql, cache_schema.json',
                'assigned_to': 'BA'
            },
            {
                'name': 'T03.06 - Configure Vertex AI Cost Monitoring',
                'description': 'Setup budget alerts and monitoring dashboards for Smart Vertex AI deployment. Set alert at $20/day threshold. Total budget: $442/month.',
                'notes': 'Daily cost monitoring to ensure staying within $442/month budget. Alerts for anomalies. Dashboard tracks endpoint usage, batch job costs, and API calls.',
                'priority': 'Medium',
                'status': 'Pending',
                'artifacts': 'monitoring_config.yaml, dashboard_template.json',
                'assigned_to': 'CE'
            }
        ]
    },
    'P04_S01': {  # Performance Optimization Phase
        'tasks': [
            {
                'name': 'T04.01 - Optimize Critical Endpoint Performance',
                'description': 'Fine-tune the 5 critical endpoints for <100ms latency. Implement caching, connection pooling, and request batching.',
                'notes': 'Target: p50 < 50ms, p99 < 100ms. Implement warm-up requests, optimize model serving containers, tune auto-scaling parameters.',
                'priority': 'High',
                'status': 'Pending',
                'artifacts': 'endpoint_optimization.py, performance_metrics.json',
                'assigned_to': 'BA'
            },
            {
                'name': 'T04.02 - Validate Batch Prediction Accuracy',
                'description': 'Verify all 191 batch models maintain 97% RÂ² accuracy. Compare batch vs real-time predictions for consistency.',
                'notes': 'Run validation suite comparing batch predictions against test data. Ensure no accuracy degradation from model serialization or batch processing.',
                'priority': 'High',
                'status': 'Pending',
                'artifacts': 'batch_validation.py, accuracy_report.csv',
                'assigned_to': 'BA'
            },
            {
                'name': 'T04.03 - Implement Intelligent Request Routing',
                'description': 'Create smart routing logic to dynamically promote high-traffic models from batch to endpoint based on usage patterns.',
                'notes': 'Monitor request patterns, auto-promote models exceeding 1000 requests/hour to endpoints. Auto-demote low-traffic endpoints to batch.',
                'priority': 'Medium',
                'status': 'Pending',
                'artifacts': 'smart_router.py, routing_rules.yaml',
                'assigned_to': 'CE'
            }
        ]
    }
}

def update_vertex_tasks():
    """Update all Vertex AI tasks to reflect Smart Architecture"""

    print("ðŸ” Finding existing Vertex AI tasks...")

    # Search for all Vertex AI related tasks
    all_tasks = tasks_table.all()
    vertex_tasks = []

    for task in all_tasks:
        name = task['fields'].get('name', '')
        desc = task['fields'].get('description', '')

        # Identify Vertex AI related tasks
        if any(keyword in name.lower() or keyword in desc.lower()
               for keyword in ['vertex', 'endpoint', 'deploy', 'model', 'prediction']):
            vertex_tasks.append(task)

    print(f"Found {len(vertex_tasks)} Vertex AI related tasks")

    # Mark old tasks as obsolete
    obsolete_count = 0
    for task in vertex_tasks:
        task_name = task['fields'].get('name', '')

        # Check if this is an old 196-endpoint task
        if '196' in task_name or 'all models' in task_name.lower() or 'full deployment' in task_name.lower():
            update = {
                'status': 'Cancelled',
                'notes': f"OBSOLETE: Replaced by Smart Vertex AI Architecture ($442/month). Original approach would cost $13,420/month. {task['fields'].get('notes', '')}",
                'priority': 'Low'
            }
            tasks_table.update(task['id'], update)
            obsolete_count += 1
            print(f"  âŒ Marked obsolete: {task_name}")

    print(f"\nâœ… Marked {obsolete_count} tasks as obsolete")

    # Add new Smart Vertex AI tasks
    print("\nðŸ“ Adding Smart Vertex AI tasks...")
    added_count = 0
    updated_count = 0

    for phase_stage, phase_data in SMART_VERTEX_TASKS.items():
        phase, stage = phase_stage.split('_')

        for task_data in phase_data['tasks']:
            # Check if task already exists
            existing = None
            for task in all_tasks:
                if task['fields'].get('name', '') == task_data['name']:
                    existing = task
                    break

            task_fields = {
                'name': task_data['name'],
                'description': task_data['description'],
                'notes': task_data['notes'],
                'priority': task_data['priority'],
                'status': task_data['status'],
                'artifacts': task_data['artifacts'],
                'assigned_to': task_data['assigned_to'],
                'phase_link': [f"rec{phase}Phase"],  # Link to phase
                'stage_link': [f"rec{phase}{stage}Stage"],  # Link to stage
                'plan_link': ['recPlanBQXMLV3'],  # Link to plan
                'score': 95  # High score for smart approach
            }

            if existing:
                # Update existing task
                tasks_table.update(existing['id'], task_fields)
                updated_count += 1
                print(f"  âœï¸ Updated: {task_data['name']}")
            else:
                # Create new task
                tasks_table.create(task_fields)
                added_count += 1
                print(f"  âœ… Added: {task_data['name']}")

    print(f"\nðŸ“Š Summary:")
    print(f"  - Obsolete tasks marked: {obsolete_count}")
    print(f"  - New tasks added: {added_count}")
    print(f"  - Tasks updated: {updated_count}")

    # Update phase descriptions
    print("\nðŸ“‹ Updating phase descriptions...")

    phases_table = api.table(BASE_ID, 'Phases')
    phases = phases_table.all()

    for phase in phases:
        if 'P03' in phase['fields'].get('name', ''):
            phases_table.update(phase['id'], {
                'description': 'Smart Vertex AI Deployment - Tiered architecture with 5 critical endpoints + 191 batch predictions. Total cost: $442/month (97% savings vs naive approach).',
                'notes': 'Implements intelligent resource allocation: real-time endpoints for high-traffic pairs, batch processing for others. Unified API provides seamless access to all 196 models.'
            })
            print(f"  âœ… Updated Phase P03 description")
        elif 'P04' in phase['fields'].get('name', ''):
            phases_table.update(phase['id'], {
                'description': 'Performance Optimization - Fine-tune Smart Vertex AI architecture for optimal latency and cost efficiency.',
                'notes': 'Focus on <100ms latency for critical pairs, hourly refresh for batch predictions, and intelligent routing based on usage patterns.'
            })
            print(f"  âœ… Updated Phase P04 description")

    print("\nâœ¨ AirTable alignment complete!")
    print(f"ðŸ’° New approach: $442/month")
    print(f"ðŸ’¸ Savings: $12,978/month (97%)")
    print(f"âš¡ Implementation time: 4 hours (vs 73 hours)")

if __name__ == "__main__":
    update_vertex_tasks()