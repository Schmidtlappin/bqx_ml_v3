#!/usr/bin/env python3
"""
Fix the remaining 30 tasks that failed due to undefined variables.
"""

import os
import json
import time
from datetime import datetime
from pyairtable import Api

# AirTable configuration
BASE_ID = os.getenv('AIRTABLE_BASE_ID')
API_KEY = os.getenv('AIRTABLE_API_KEY')

# Load from secrets if not in environment
if not API_KEY or not BASE_ID:
    try:
        with open('/home/micha/bqx_ml_v3/.secrets/github_secrets.json', 'r') as f:
            secrets = json.load(f)
            API_KEY = API_KEY or secrets['secrets']['AIRTABLE_API_KEY']['value']
            BASE_ID = BASE_ID or secrets['secrets']['AIRTABLE_BASE_ID']['value']
    except:
        print("Warning: Could not load AirTable credentials")

# Initialize API
api = Api(API_KEY)
base = api.base(BASE_ID)
tasks_table = base.table('Tasks')

# List of failed task IDs
FAILED_TASKS = [
    'MP03.P09.S01.T99', 'MP03.P04.S02.T03', 'MP03.P06.S01.T01',
    'MP03.P05.S02.T01', 'MP03.P03.S02.T01', 'MP03.P07.S02.T02',
    'MP03.P06.S05.T02', 'MP03.P05.S04.T97', 'MP03.P06.S01.T02',
    'MP03.P07.S01.T03', 'MP03.P06.S02.T02', 'MP03.P06.S08.T02',
    'MP03.P07.S03.T03', 'MP03.P07.S02.T03', 'MP03.P07.S03.T02',
    'MP03.P06.S05.T03', 'MP03.P06.S03.T01', 'MP03.P06.S04.T02',
    'MP03.P06.S04.T03', 'MP03.P06.S04.T01', 'MP03.P06.S03.T03',
    'MP03.P06.S05.T01', 'MP03.P02.S04.T01', 'MP03.P04.S05.T01',
    'MP03.P04.S03.T01', 'MP03.P06.S01.T03', 'MP03.P06.S02.T01',
    'MP03.P06.S03.T02', 'MP03.P06.S02.T03', 'MP03.P04.S02.T02'
]

def generate_feature_engineering_notes(task_id, name):
    """Generate notes for feature engineering tasks."""

    windows = [45, 90, 180, 360, 720, 1440, 2880]

    return f"""## Implementation Guide - {task_id}

### BigQuery Feature Engineering SQL
```sql
-- BQX Feature Calculation for {task_id}
-- Using ROWS BETWEEN for INTERVAL-CENTRIC approach
WITH bqx_features AS (
  SELECT
    pair,
    interval_time,
    close_price,

    -- BQX calculations for each window
    """ + ',\n    '.join([f"""
    (close_price - LAG(close_price, {w}) OVER (
      PARTITION BY pair ORDER BY interval_time
      ROWS BETWEEN {w} PRECEDING AND CURRENT ROW
    )) / LAG(close_price, {w}) OVER (
      PARTITION BY pair ORDER BY interval_time
    ) * 100 AS bqx_{w}""" for w in windows]) + """

  FROM `bqx-ml-v3.features.idx_ohlcv`
  WHERE pair IN ('EURUSD', 'GBPUSD', 'USDJPY') -- 28 pairs total
)

SELECT * FROM bqx_features
WHERE interval_time >= '2022-07-01'
```

### Python Implementation
```python
import pandas as pd
import numpy as np
from google.cloud import bigquery

def calculate_bqx_features(df, windows={windows}):
    '''Calculate BQX momentum features'''

    for window in windows:
        # Calculate BQX using pandas rolling windows
        df[f'bqx_{"{window}"}'] = (
            (df['close'] - df['close'].shift(window)) /
            df['close'].shift(window) * 100
        )

    return df

# Feature validation
def validate_features(df):
    '''Ensure no data leakage'''

    for col in df.columns:
        if 'bqx_' in col:
            # Check for NaN handling
            assert df[col].isna().sum() < len(df) * 0.1

            # Check for reasonable ranges
            assert df[col].abs().max() < 100

    return True
```

### Testing Strategy
```python
import pytest

def test_bqx_calculation():
    '''Test BQX feature calculation'''

    # Create sample data
    test_data = pd.DataFrame({{
        'close': [100, 102, 104, 103, 105, 107, 106]
    }})

    # Calculate BQX
    result = calculate_bqx_features(test_data, windows=[2, 3])

    # Verify calculations
    assert 'bqx_2' in result.columns
    assert 'bqx_3' in result.columns

    # Check specific values
    expected_bqx_2 = ((104 - 100) / 100) * 100  # 4%
    assert abs(result.iloc[2]['bqx_2'] - expected_bqx_2) < 0.01

def test_no_future_leakage():
    '''Ensure no future data leakage'''

    # Implementation ensures LAG only, never LEAD
    pass
```

### Quality Gates
- R¬≤ >= 0.35 for all windows
- RMSE <= 0.15
- Directional Accuracy >= 55%
- No data leakage (LAG only, no LEAD)
- 100% test coverage

‚úÖ Ready for BQX ML V3 implementation
"""

def generate_deployment_notes(task_id, name):
    """Generate notes for deployment tasks."""

    return f"""## Deployment Implementation - {task_id}

### Vertex AI Deployment Configuration
```python
from google.cloud import aiplatform

# Initialize Vertex AI
aiplatform.init(
    project='bqx-ml-v3',
    location='us-central1'
)

# Deploy model to endpoint
def deploy_model(model_id, endpoint_name):
    '''Deploy XGBoost model to Vertex AI endpoint'''

    # Get or create endpoint
    endpoints = aiplatform.Endpoint.list(
        filter=f'display_name="{endpoint_name}"'
    )

    if endpoints:
        endpoint = endpoints[0]
    else:
        endpoint = aiplatform.Endpoint.create(
            display_name=endpoint_name,
            description=f'BQX ML V3 - {task_id}'
        )

    # Deploy model
    model = aiplatform.Model(model_id)

    deployed_model = model.deploy(
        endpoint=endpoint,
        deployed_model_display_name=f'{task_id}_model',
        machine_type='n1-standard-4',
        min_replica_count=1,
        max_replica_count=5,
        accelerator_type=None,
        accelerator_count=0,
        traffic_percentage=100,
        sync=False
    )

    print(f"Model deployed to: {{endpoint.resource_name}}")
    return endpoint

# Batch prediction configuration
def setup_batch_prediction(model_id, input_uri, output_uri):
    '''Configure batch prediction job'''

    model = aiplatform.Model(model_id)

    batch_prediction_job = model.batch_predict(
        job_display_name=f'{task_id}_batch_predict',
        instances_format='bigquery',
        predictions_format='bigquery',
        bigquery_source=input_uri,
        bigquery_destination_prefix=output_uri,
        machine_type='n1-standard-8',
        max_replica_count=10,
        sync=False
    )

    return batch_prediction_job
```

### Monitoring Setup
```python
from google.cloud import monitoring_v3

def setup_monitoring(endpoint_name):
    '''Configure endpoint monitoring'''

    client = monitoring_v3.MetricServiceClient()
    project = 'bqx-ml-v3'

    # Create custom metrics
    metrics = [
        'prediction_latency',
        'prediction_error_rate',
        'model_drift_score'
    ]

    for metric_name in metrics:
        descriptor = monitoring_v3.MetricDescriptor()
        descriptor.type = f'custom.googleapis.com/ml/{metric_name}'
        descriptor.metric_kind = monitoring_v3.MetricDescriptor.MetricKind.GAUGE
        descriptor.value_type = monitoring_v3.MetricDescriptor.ValueType.DOUBLE
        descriptor.display_name = metric_name.replace('_', ' ').title()

        client.create_metric_descriptor(
            name=f'projects/{project}',
            metric_descriptor=descriptor
        )

    # Set up alerts
    alert_config = {{
        'display_name': f'{task_id} Performance Alert',
        'conditions': [{{
            'display_name': 'High Latency',
            'condition_threshold': {{
                'filter': f'resource.type="aiplatform.googleapis.com/Endpoint"',
                'comparison': 'COMPARISON_GT',
                'threshold_value': 1000,  # ms
                'duration': '60s'
            }}
        }}]
    }}

    return alert_config
```

### Load Testing
```python
import asyncio
import aiohttp
import time

async def load_test_endpoint(endpoint_url, num_requests=1000):
    '''Test endpoint performance'''

    async with aiohttp.ClientSession() as session:
        tasks = []

        for i in range(num_requests):
            payload = {{
                'instances': [{{
                    'pair': 'EURUSD',
                    'features': [0.5, -0.2, 1.3, 0.8]  # BQX values
                }}]
            }}

            task = session.post(endpoint_url, json=payload)
            tasks.append(task)

        start_time = time.time()
        responses = await asyncio.gather(*tasks)
        end_time = time.time()

        # Calculate metrics
        total_time = end_time - start_time
        avg_latency = (total_time / num_requests) * 1000

        successful = sum(1 for r in responses if r.status == 200)
        error_rate = (num_requests - successful) / num_requests

        print(f"Average latency: {{avg_latency:.2f}} ms")
        print(f"Error rate: {{error_rate:.2%}}")

        return avg_latency, error_rate

# Run load test
asyncio.run(load_test_endpoint('https://endpoint-url.com', 1000))
```

### Rollback Strategy
```python
def rollback_deployment(endpoint_name, previous_model_id):
    '''Rollback to previous model version'''

    endpoint = aiplatform.Endpoint.list(
        filter=f'display_name="{endpoint_name}"'
    )[0]

    # Undeploy current model
    for deployed_model in endpoint.list_models():
        endpoint.undeploy(deployed_model_id=deployed_model.id)

    # Deploy previous version
    previous_model = aiplatform.Model(previous_model_id)
    previous_model.deploy(
        endpoint=endpoint,
        machine_type='n1-standard-4',
        traffic_percentage=100
    )

    print(f"Rolled back to model: {{previous_model_id}}")
```

‚úÖ Ready for production deployment
"""

def fix_remaining_tasks():
    """Fix the 30 tasks that failed."""

    print("=" * 80)
    print("FIXING REMAINING TASK NOTES")
    print(f"Timestamp: {datetime.now().isoformat()}")
    print("=" * 80)

    # Get all tasks
    print("\nüì• Loading tasks...")
    all_tasks = tasks_table.all()

    # Filter to failed tasks
    tasks_to_fix = []
    for task in all_tasks:
        task_id = task['fields'].get('task_id', '')
        if task_id in FAILED_TASKS:
            tasks_to_fix.append(task)

    print(f"  Found {len(tasks_to_fix)} tasks to fix")

    success_count = 0

    for task in tasks_to_fix:
        task_id = task['fields'].get('task_id', '')
        name = task['fields'].get('name', '')

        try:
            # Determine task type and generate appropriate notes
            if any(term in task_id for term in ['P06', 'P07', 'P05.S02', 'P04.S03']):
                # Feature engineering tasks
                notes = generate_feature_engineering_notes(task_id, name)
            else:
                # Deployment tasks
                notes = generate_deployment_notes(task_id, name)

            # Update task
            tasks_table.update(task['id'], {'notes': notes})

            success_count += 1
            print(f"  ‚úÖ {task_id} - Fixed with {len(notes)} chars")

        except Exception as e:
            print(f"  ‚ùå {task_id} - Error: {e}")

        # Rate limiting
        time.sleep(0.5)

    # Summary
    print("\n" + "=" * 80)
    print("FIX COMPLETE")
    print("=" * 80)
    print(f"  Tasks fixed: {success_count}/{len(tasks_to_fix)}")
    print(f"‚úÖ Completed at: {datetime.now().isoformat()}")

    return success_count == len(tasks_to_fix)

def main():
    """Main entry point."""
    success = fix_remaining_tasks()

    if success:
        print("\n‚úÖ SUCCESS! All remaining tasks have meaningful notes")
        return 0
    else:
        print("\n‚ö†Ô∏è Some tasks could not be fixed")
        return 1

if __name__ == "__main__":
    exit(main())