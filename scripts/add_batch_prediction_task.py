#!/usr/bin/env python3
"""
Add missing Vertex AI batch prediction task to AirTable.
This completes the Vertex AI process coverage to 100% (18/18).
"""

import os
import json
import time
from datetime import datetime
from pyairtable import Api

# AirTable configuration
BASE_ID = os.getenv('AIRTABLE_BASE_ID')
API_KEY = os.getenv('AIRTABLE_API_KEY')

# Load from secrets if not in environment
if not API_KEY or not BASE_ID:
    try:
        with open('/home/micha/bqx_ml_v3/.secrets/github_secrets.json', 'r') as f:
            secrets = json.load(f)
            API_KEY = API_KEY or secrets['secrets']['AIRTABLE_API_KEY']['value']
            BASE_ID = BASE_ID or secrets['secrets']['AIRTABLE_BASE_ID']['value']
    except:
        print("Warning: Could not load AirTable credentials")

# Initialize API
api = Api(API_KEY)
base = api.base(BASE_ID)
tasks_table = base.table('Tasks')
stages_table = base.table('Stages')

def add_batch_prediction_task():
    """Add batch prediction task to complete Vertex AI coverage."""
    print("=" * 80)
    print("ADDING BATCH PREDICTION TASK FOR VERTEX AI")
    print(f"Timestamp: {datetime.now().isoformat()}")
    print("=" * 80)

    # Find the appropriate stage for batch prediction
    # This should go in P09 (Production Deployment) or P08 (Model Evaluation)
    stages = stages_table.all()

    # Look for production deployment stage
    target_stage = None
    for stage in stages:
        stage_id = stage['fields'].get('stage_id', '')
        name = stage['fields'].get('name', '').lower()

        # Find stage related to production deployment or batch processing
        if 'MP03.P09.S03' in stage_id or 'batch' in name or 'production' in name:
            target_stage = stage
            break
        elif 'MP03.P08' in stage_id and 'evaluation' in name:
            target_stage = stage
            break

    # If no specific stage found, use P09.S03 (Production deployment)
    if not target_stage:
        # Create a new task in production deployment stage
        for stage in stages:
            if stage['fields'].get('stage_id') == 'MP03.P09.S03':
                target_stage = stage
                break

    if not target_stage:
        print("‚ö†Ô∏è Could not find appropriate stage for batch prediction task")
        print("   Creating task in Model Evaluation phase instead...")
        # Find any P08 stage
        for stage in stages:
            stage_id = stage['fields'].get('stage_id', '')
            if 'MP03.P08' in stage_id:
                target_stage = stage
                break

    if not target_stage:
        print("‚ùå Could not find any suitable stage for batch prediction task")
        return False

    stage_id = target_stage['fields'].get('stage_id', '')
    print(f"\n‚úÖ Found target stage: {stage_id}")
    print(f"   Stage name: {target_stage['fields'].get('name', '')}")

    # Create the batch prediction task
    task_data = {
        'task_id': f"{stage_id}.T99",  # Using T99 to avoid conflicts
        'description': """**Configure Vertex AI Batch Prediction Jobs**

**Objective**: Implement scheduled batch prediction jobs for all 28 currency pair models using Vertex AI Batch Prediction service.

**Context**: This task completes the Vertex AI process coverage by adding batch prediction capabilities for large-scale, scheduled inference operations across all BQX ML V3 models.

**Key Requirements**:
‚Ä¢ Configure batch prediction jobs for all 28 currency pairs
‚Ä¢ Set up scheduled execution (hourly, daily, weekly options)
‚Ä¢ Implement INTERVAL-CENTRIC feature preparation for batch inputs
‚Ä¢ Output predictions to BigQuery for downstream consumption""",

        'notes': """### Vertex AI Batch Prediction Implementation

**Technical Specifications**:
‚Ä¢ Use Vertex AI Batch Prediction API for scalable inference
‚Ä¢ Input format: BigQuery tables with feature vectors
‚Ä¢ Output format: BigQuery tables with predictions and confidence scores
‚Ä¢ Support for multiple prediction horizons (45i, 90i, 180i, 360i, 720i, 1440i, 2880i)

**Implementation Steps**:
1. **Prepare Batch Input Pipeline**:
   - Create BigQuery views for feature extraction
   - Ensure INTERVAL-CENTRIC window calculations
   - Validate feature completeness and quality
   - Format as required by Vertex AI (JSONL or BigQuery)

2. **Configure Batch Prediction Jobs**:
   ```python
   from google.cloud import aiplatform

   def create_batch_prediction_job(model_name, input_uri, output_uri):
       job = aiplatform.BatchPredictionJob.create(
           job_display_name=f"bqx_batch_pred_{model_name}",
           model_name=model_name,
           input_dataset_format="bigquery",
           input_dataset_uri=input_uri,
           output_dataset_format="bigquery",
           output_dataset_uri=output_uri,
           machine_type="n1-standard-4",
           max_replica_count=10
       )
       return job
   ```

3. **Schedule Batch Jobs**:
   - Use Cloud Scheduler for regular execution
   - Implement different schedules for different horizons:
     * Short-term (45i, 90i): Hourly
     * Medium-term (180i, 360i): Every 4 hours
     * Long-term (720i+): Daily

4. **Output Processing**:
   - Write predictions to structured BigQuery tables
   - Include prediction timestamp and model version
   - Calculate prediction confidence scores
   - Implement data retention policies

**BigQuery Schema**:
```sql
CREATE TABLE bqx_ml_predictions.batch_predictions_${pair} (
    prediction_timestamp TIMESTAMP,
    bar_start_time TIMESTAMP,
    model_version STRING,
    horizon_intervals INT64,
    predicted_bqx FLOAT64,
    confidence_lower FLOAT64,
    confidence_upper FLOAT64,
    feature_importance ARRAY<STRUCT<
        feature_name STRING,
        importance_score FLOAT64
    >>
)
PARTITION BY DATE(prediction_timestamp)
CLUSTER BY model_version, horizon_intervals;
```

**Monitoring & Alerting**:
‚Ä¢ Track job completion rates
‚Ä¢ Monitor prediction latency
‚Ä¢ Alert on job failures or anomalies
‚Ä¢ Dashboard for batch prediction metrics

**Cost Optimization**:
‚Ä¢ Use preemptible instances when possible
‚Ä¢ Batch multiple models together
‚Ä¢ Implement intelligent scheduling based on market hours
‚Ä¢ Archive old predictions to Cloud Storage

**Quality Assurance**:
‚Ä¢ Validate input feature distributions
‚Ä¢ Check for prediction drift
‚Ä¢ Compare batch vs online predictions
‚Ä¢ Implement A/B testing framework

**Integration Points**:
‚Ä¢ Upstream: Feature engineering pipeline must be complete
‚Ä¢ Downstream: Trading systems consume predictions
‚Ä¢ Monitoring: Integrate with existing MLOps dashboard

**Success Metrics**:
‚Ä¢ All 28 models have batch prediction configured
‚Ä¢ 99.9% job success rate
‚Ä¢ Predictions available within SLA (< 5 minutes)
‚Ä¢ Cost per prediction < $0.001

**INTERVAL-CENTRIC Compliance**:
‚Ä¢ All feature windows use ROWS BETWEEN
‚Ä¢ No time-based calculations in feature prep
‚Ä¢ Consistent interval handling across all models
‚Ä¢ Proper handling of market gaps (weekends, holidays)

---
*This task ensures comprehensive Vertex AI coverage and enables scalable batch inference for the BQX ML V3 project.*""",

        'status': 'Todo',
        'priority': 'High',
        'stage_link': [target_stage['id']]
    }

    try:
        # Create the task
        print("\nüìù Creating batch prediction task...")
        new_task = tasks_table.create(task_data)
        print(f"‚úÖ Successfully created task: {new_task['fields']['task_id']}")

        # Update the stage's task_link to include this new task
        current_task_links = target_stage['fields'].get('task_link', [])
        current_task_links.append(new_task['id'])

        stages_table.update(target_stage['id'], {
            'task_link': current_task_links
        })
        print(f"‚úÖ Updated stage {stage_id} with new task link")

        return True

    except Exception as e:
        print(f"‚ùå Error creating task: {e}")
        return False

def verify_vertex_ai_coverage():
    """Verify that all Vertex AI processes are now covered."""
    print("\n" + "=" * 80)
    print("VERIFYING VERTEX AI PROCESS COVERAGE")
    print("=" * 80)

    # Get all tasks
    tasks = tasks_table.all()

    # Search for Vertex AI related tasks
    vertex_ai_tasks = []
    batch_prediction_found = False

    for task in tasks:
        desc = task['fields'].get('description', '').lower()
        notes = task['fields'].get('notes', '').lower()
        content = desc + ' ' + notes

        if 'vertex ai' in content or 'vertex' in content:
            vertex_ai_tasks.append(task['fields'].get('task_id', ''))

            if 'batch prediction' in content:
                batch_prediction_found = True

    print(f"\nüìä Vertex AI Coverage Analysis:")
    print(f"  Total Vertex AI related tasks: {len(vertex_ai_tasks)}")
    print(f"  Batch Prediction task present: {'‚úÖ Yes' if batch_prediction_found else '‚ùå No'}")

    if batch_prediction_found:
        print("\n‚úÖ VERTEX AI COVERAGE NOW COMPLETE (18/18 processes)")
        print("   All required Vertex AI processes are covered in AirTable")
    else:
        print("\n‚ö†Ô∏è Batch prediction task may need manual verification")

    return batch_prediction_found

def main():
    """Main execution."""
    print("=" * 80)
    print("VERTEX AI BATCH PREDICTION TASK ADDITION")
    print("=" * 80)

    # Add the batch prediction task
    success = add_batch_prediction_task()

    if success:
        # Verify coverage
        complete = verify_vertex_ai_coverage()

        print("\n" + "=" * 80)
        print("TASK ADDITION COMPLETE")
        print("=" * 80)

        if complete:
            print("\nüéâ SUCCESS! Vertex AI process coverage is now 100% (18/18)")
            print("   The batch prediction task has been successfully added to AirTable")
        else:
            print("\n‚úÖ Batch prediction task added successfully")
            print("   Please verify in AirTable that it appears correctly")

        print("\nüìä Next Steps:")
        print("  1. Review the new task in AirTable")
        print("  2. Assign to appropriate team member")
        print("  3. Update timeline and dependencies as needed")
        print("  4. Begin implementation planning")
    else:
        print("\n‚ùå Failed to add batch prediction task")
        print("   Please check AirTable permissions and try again")

    print(f"\nüèÅ Completed at: {datetime.now().isoformat()}")
    return 0 if success else 1

if __name__ == "__main__":
    exit(main())