{
  "mandate_id": "BACKUP_DISASTER_RECOVERY",
  "version": "2.0",
  "created": "2025-11-28",
  "last_updated": "2025-11-28T19:55:00Z",
  "purpose": "Establish protocols for continuous backup and disaster recovery of BQX-ML-V3 critical assets",

  "critical_directive": {
    "DISASTER_RECOVERY_BACKUP": {
      "mandate": "Maintain continuous, automated backups of ALL BQX-ML-V3 assets including BigQuery tables to Box.com for disaster recovery",
      "date_issued": "2025-11-28",
      "enforcement": "MANDATORY",
      "rationale": {
        "primary": "Business continuity - ability to recover from complete GCP failures or data loss",
        "secondary": "Geographic and infrastructure independence - Box.com is completely separate from GCP",
        "tertiary": "Unlimited storage capacity - Box.com can store full BQ table exports",
        "quaternary": "Audit trail - version history of all project artifacts"
      }
    }
  },

  "provider_comparison": {
    "google_drive": {
      "role": "Working Backup",
      "strengths": [
        "Fast access from GCP instances",
        "Integrated with Google ecosystem",
        "Good for day-to-day file sync"
      ],
      "limitations": [
        "Storage quota limits (~15GB free, paid plans limited)",
        "Part of GCP infrastructure - NOT independent",
        "If GCP fails, GDrive access may be affected",
        "Not suitable for large BQ table exports (TB-scale)"
      ],
      "use_case": "Project files only (intelligence, docs, scripts, configs)",
      "disaster_recovery_suitability": "LOW - same infrastructure as primary"
    },
    "box_com": {
      "role": "TRUE Disaster Recovery",
      "strengths": [
        "Unlimited storage (enterprise plan)",
        "Completely independent from GCP",
        "Survives complete GCP failure or account loss",
        "Can store full BigQuery exports (TB-scale)",
        "Version history and audit trail",
        "Enterprise-grade security and compliance"
      ],
      "limitations": [
        "API rate limits for large uploads",
        "Slower than GDrive for GCP instances"
      ],
      "use_case": "EVERYTHING - files AND BigQuery table exports",
      "disaster_recovery_suitability": "HIGH - independent infrastructure"
    },
    "decision_rationale": {
      "summary": "Box.com is the ONLY true disaster recovery solution",
      "key_insight": "GDrive is part of GCP. If GCP fails or access is lost, GDrive may be inaccessible too",
      "mandate": "ALL data including BigQuery tables MUST be backed up to Box.com",
      "gdrive_role": "Convenience backup for quick file access, NOT disaster recovery"
    }
  },

  "backup_targets": {
    "tier_1_files": {
      "description": "Project files - sync to BOTH providers",
      "gdrive": true,
      "box": true,
      "items": [
        {
          "name": "Intelligence Files",
          "path": "/intelligence/",
          "reason": "Project knowledge, mandates, context - irreplaceable institutional memory",
          "sync_frequency": "On every change"
        },
        {
          "name": "Configuration Files",
          "path": "/configs/",
          "reason": "Infrastructure and model configurations",
          "sync_frequency": "On every change"
        },
        {
          "name": "Agent Communications",
          "path": "/.claude/sandbox/communications/",
          "reason": "Decision history and agent coordination logs",
          "sync_frequency": "Daily"
        },
        {
          "name": "Documentation",
          "path": "/docs/",
          "reason": "Technical documentation and specifications",
          "sync_frequency": "Daily"
        },
        {
          "name": "Scripts",
          "path": "/scripts/",
          "reason": "Automation and processing scripts",
          "sync_frequency": "On significant changes"
        }
      ]
    },
    "tier_2_bigquery": {
      "description": "BigQuery table exports - Box.com ONLY (too large for GDrive)",
      "gdrive": false,
      "box": true,
      "reason": "TB-scale data exceeds GDrive limits; must use unlimited Box.com storage",
      "export_format": {
        "format": "Parquet",
        "compression": "Snappy (built-in)",
        "rationale": [
          "10-20x better compression than JSON",
          "Preserves schema and data types exactly",
          "Columnar format optimized for analytics",
          "Native BigQuery support for import/export",
          "Faster read/write operations"
        ]
      },
      "items": [
        {
          "name": "Raw OHLCV Data",
          "dataset": "bqx_bq_uscen1",
          "tables": 2463,
          "estimated_size": "~2TB compressed",
          "export_method": "BQ Export -> GCS -> Download -> Box.com",
          "sync_frequency": "Quarterly or on significant changes",
          "priority": "HIGH - foundational data"
        },
        {
          "name": "Feature Tables",
          "dataset": "bqx_ml_v3_features",
          "current_tables": 505,
          "target_tables": 1736,
          "estimated_size": "~500GB compressed",
          "export_method": "BQ Export -> GCS -> Download -> Box.com",
          "sync_frequency": "After each Phase completion",
          "priority": "HIGH - computed features"
        },
        {
          "name": "Model Artifacts",
          "dataset": "bqx_ml_v3_models",
          "current_tables": 16,
          "target_tables": 196,
          "estimated_size": "~50GB compressed",
          "export_method": "BQ Export -> GCS -> Download -> Box.com",
          "sync_frequency": "After each training batch",
          "priority": "CRITICAL - trained models"
        },
        {
          "name": "Predictions",
          "dataset": "bqx_ml_v3_predictions",
          "current_tables": 0,
          "target_tables": "TBD",
          "export_method": "BQ Export -> GCS -> Download -> Box.com",
          "sync_frequency": "Weekly during production",
          "priority": "MEDIUM - can regenerate from models"
        },
        {
          "name": "Analytics",
          "dataset": "bqx_ml_v3_analytics",
          "current_tables": 0,
          "target_tables": "TBD",
          "export_method": "BQ Export -> GCS -> Download -> Box.com",
          "sync_frequency": "Weekly",
          "priority": "LOW - can regenerate"
        }
      ]
    }
  },

  "backup_infrastructure": {
    "working_backup": {
      "provider": "Google Drive",
      "remote": "gdrive:bqx_ml_v3",
      "tool": "rclone",
      "script": "scripts/sync-bqx-project.sh",
      "purpose": "Quick access working backup - FILES ONLY",
      "limitations": "Storage quota, same infrastructure as GCP",
      "disaster_recovery": false,
      "status": "ACTIVE"
    },
    "disaster_recovery": {
      "provider": "Box.com",
      "folder_id": "353414610676",
      "folder_name": "bqx-ml-v3",
      "auth_method": "JWT",
      "jwt_config": "/home/micha/.secrets/box_jwt_config.json",
      "tool": "Box SDK (box_sdk_gen)",
      "scripts": {
        "files": "scripts/sync-box-backup.py",
        "bigquery": "containers/bq-to-box/sync_service.py"
      },
      "purpose": "TRUE disaster recovery - FILES AND BigQuery tables",
      "advantages": "Unlimited storage, independent infrastructure",
      "disaster_recovery": true,
      "status": "ACTIVE"
    },
    "cloud_run_service": {
      "name": "bq-to-box-sync",
      "url": "https://bq-to-box-sync-499681702492.us-central1.run.app",
      "region": "us-central1",
      "image": "us-central1-docker.pkg.dev/bqx-ml/bqx-containers/bq-to-box-sync:latest",
      "memory": "2Gi",
      "timeout": "3600s",
      "authentication": "IAM (no public access)",
      "endpoints": {
        "health": "GET /",
        "sync_dataset": "POST /sync/<dataset>",
        "sync_tables": "POST /sync { dataset, tables }"
      },
      "trigger_example": "curl -X POST $URL/sync/bqx_ml_v3_models -H 'Authorization: Bearer $(gcloud auth print-identity-token)'",
      "status": "DEPLOYED"
    }
  },

  "sync_protocol": {
    "on_user_request": {
      "action": "Sync workspace files to BOTH GDrive AND Box.com",
      "script": "scripts/sync-workspace.sh",
      "duration": "~5 minutes"
    },
    "daily_automated": {
      "action": "Auto-sync critical files to both providers",
      "schedule": "00:00 UTC",
      "script": "systemd timer (bqx-backup.timer)",
      "status": "PLANNED"
    },
    "bigquery_backup": {
      "action": "Export BQ tables to Box.com via Cloud Run",
      "trigger": "Cloud Scheduler or manual API call",
      "service": "bq-to-box-sync (Cloud Run)",
      "duration": "1-8 hours depending on dataset",
      "blocking": false,
      "note": "Serverless - scales automatically, no VM management"
    },
    "scheduled_sync": {
      "models": { "schedule": "Daily 2 AM UTC", "priority": "CRITICAL" },
      "features": { "schedule": "Weekly Sunday 3 AM UTC", "priority": "HIGH" },
      "predictions": { "schedule": "Weekly Monday 4 AM UTC", "priority": "MEDIUM" },
      "analytics": { "schedule": "Monthly 1st 5 AM UTC", "priority": "LOW" },
      "ohlcv": { "schedule": "Quarterly Jan/Apr/Jul/Oct 1st 1 AM UTC", "priority": "HIGH" }
    }
  },

  "execution_model": {
    "file_sync": {
      "duration": "Minutes",
      "blocking": false,
      "parallelism": "Can run while BA works"
    },
    "bigquery_export": {
      "duration": "Hours (4-8)",
      "blocking": false,
      "parallelism": "MUST run in background",
      "note": "Long-running process - do NOT block BA execution"
    },
    "expectation": "Backup operations are background tasks that never interrupt active work"
  },

  "recovery_procedures": {
    "scenario_1_file_loss": {
      "description": "Local files lost or corrupted",
      "recovery_source": "Box.com (primary) or GDrive (secondary)",
      "steps": [
        "Download from Box.com bqx-ml-v3 folder",
        "Restore to /home/micha/bqx_ml_v3/",
        "Verify intelligence files integrity"
      ],
      "rto": "< 1 hour"
    },
    "scenario_2_gcp_failure": {
      "description": "GCP project unavailable or data loss",
      "recovery_source": "Box.com ONLY (GDrive is part of GCP)",
      "steps": [
        "Access Box.com (independent of GCP)",
        "Provision new GCP project",
        "Restore BigQuery tables from Box.com exports",
        "Restore configuration and scripts",
        "Re-deploy infrastructure"
      ],
      "rto": "< 24 hours",
      "note": "This is why Box.com must have BQ exports - GDrive would be inaccessible"
    },
    "scenario_3_complete_disaster": {
      "description": "All GCP and local data lost",
      "recovery_source": "Box.com ONLY",
      "steps": [
        "Access Box.com via web or API (completely independent)",
        "Download all backups including BQ exports",
        "Rebuild entire infrastructure from Box.com data"
      ],
      "rto": "< 48 hours"
    }
  },

  "compliance_requirements": {
    "backup_verification": "Weekly verification of backup integrity",
    "retention": "Maintain 30 days of version history",
    "documentation": "Log all backup operations with timestamps",
    "testing": "Quarterly disaster recovery test (file restore from Box.com)",
    "bigquery_backup_audit": "Verify BQ exports exist in Box.com after each Phase"
  }
}
